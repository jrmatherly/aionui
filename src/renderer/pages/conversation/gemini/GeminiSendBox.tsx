import { ipcBridge } from '@/common';
import { transformMessage } from '@/common/chatLib';
import type { IResponseMessage } from '@/common/ipcBridge';
import type { TChatConversation, TokenUsageData } from '@/common/storage';
import { uuid } from '@/common/utils';
import ContextUsageIndicator from '@/renderer/components/ContextUsageIndicator';
import FilePreview from '@/renderer/components/FilePreview';
import HorizontalFileList from '@/renderer/components/HorizontalFileList';
import ThoughtDisplay, { type ThoughtData } from '@/renderer/components/ThoughtDisplay';
import SendBox from '@/renderer/components/sendbox';
import { useAutoTitle } from '@/renderer/hooks/useAutoTitle';
import { useLatestRef } from '@/renderer/hooks/useLatestRef';
import { getSendBoxDraftHook, type FileOrFolderItem } from '@/renderer/hooks/useSendBoxDraft';
import { createSetUploadFile, useSendBoxFiles } from '@/renderer/hooks/useSendBoxFiles';
import { useAddOrUpdateMessage } from '@/renderer/messages/hooks';
import { usePreviewContext } from '@/renderer/pages/conversation/preview';
import { allSupportedExts } from '@/renderer/services/FileService';
import { iconColors } from '@/renderer/theme/colors';
import { emitter, useAddEventListener } from '@/renderer/utils/emitter';
import { mergeFileSelectionItems } from '@/renderer/utils/fileSelection';
import { createLogger } from '@/renderer/utils/logger';
import { buildDisplayMessage, collectSelectedFiles } from '@/renderer/utils/messageFiles';
import { getModelContextLimit } from '@/renderer/utils/modelContextLimits';
import { Button, Message, Progress, Tag } from '@arco-design/web-react';
import { Plus } from '@icon-park/react';
import React, { useCallback, useEffect, useMemo, useRef, useState } from 'react';
import type { GeminiModelSelection } from './useGeminiModelSelection';

const log = createLogger('GeminiSendBox');

const useGeminiSendBoxDraft = getSendBoxDraftHook('gemini', {
  _type: 'gemini',
  atPath: [],
  content: '',
  uploadFile: [],
});

const useGeminiMessage = (conversation_id: string, onError?: (message: IResponseMessage) => void) => {
  const addOrUpdateMessage = useAddOrUpdateMessage();
  const [streamRunning, setStreamRunning] = useState(false); // API æµæ˜¯å¦åœ¨è¿è¡Œ
  const [hasActiveTools, setHasActiveTools] = useState(false); // æ˜¯å¦æœ‰å·¥å…·åœ¨æ‰§è¡Œæˆ–ç­‰å¾…ç¡®è®¤
  const [waitingResponse, setWaitingResponse] = useState(false); // ç­‰å¾…åç«¯å“åº”ï¼ˆå‘é€æ¶ˆæ¯ååˆ°æ”¶åˆ° start ä¹‹å‰ï¼‰
  const [thought, setThought] = useState<ThoughtData>({
    description: '',
    subject: '',
  });
  const [tokenUsage, setTokenUsage] = useState<TokenUsageData | null>(null);
  // Pending KB notification â€” stored on kb_ready, emitted as chat message on stream finish
  const pendingKbNotification = useRef<{ msgId: string; content: string } | null>(null);
  const [ingestionProgress, setIngestionProgress] = useState<{
    status: 'start' | 'ingesting' | 'success' | 'error' | 'complete' | 'stage' | 'kb_ready';
    current?: number;
    total: number;
    fileName?: string;
    successCount?: number;
    failedCount?: number;
    stage?: string;
    detail?: string;
    percent?: number;
  } | null>(null);
  // å½“å‰æ´»è·ƒçš„æ¶ˆæ¯ IDï¼Œç”¨äºè¿‡æ»¤æ—§è¯·æ±‚çš„äº‹ä»¶ï¼ˆé˜²æ­¢ abort åçš„äº‹ä»¶å¹²æ‰°æ–°è¯·æ±‚ï¼‰
  // Current active message ID to filter out events from old requests (prevents aborted request events from interfering with new ones)
  const activeMsgIdRef = useRef<string | null>(null);

  // Use refs to avoid useEffect re-subscription when these states change
  // ä½¿ç”¨ ref é¿å…çŠ¶æ€å˜åŒ–æ—¶ useEffect é‡æ–°è®¢é˜…å¯¼è‡´äº‹ä»¶ä¸¢å¤±
  const hasActiveToolsRef = useRef(hasActiveTools);
  const streamRunningRef = useRef(streamRunning);
  useEffect(() => {
    hasActiveToolsRef.current = hasActiveTools;
  }, [hasActiveTools]);
  useEffect(() => {
    streamRunningRef.current = streamRunning;
  }, [streamRunning]);

  // Think æ¶ˆæ¯èŠ‚æµï¼šé™åˆ¶æ›´æ–°é¢‘ç‡ï¼Œå‡å°‘æ¸²æŸ“æ¬¡æ•°
  // Throttle thought updates to reduce render frequency
  const thoughtThrottleRef = useRef<{
    lastUpdate: number;
    pending: ThoughtData | null;
    timer: ReturnType<typeof setTimeout> | null;
  }>({ lastUpdate: 0, pending: null, timer: null });

  const throttledSetThought = useMemo(() => {
    const THROTTLE_MS = 50; // 50ms èŠ‚æµé—´éš”
    return (data: ThoughtData) => {
      const now = Date.now();
      const ref = thoughtThrottleRef.current;

      // å¦‚æœè·ç¦»ä¸Šæ¬¡æ›´æ–°è¶…è¿‡èŠ‚æµé—´éš”ï¼Œç«‹å³æ›´æ–°
      if (now - ref.lastUpdate >= THROTTLE_MS) {
        ref.lastUpdate = now;
        ref.pending = null;
        if (ref.timer) {
          clearTimeout(ref.timer);
          ref.timer = null;
        }
        setThought(data);
      } else {
        // å¦åˆ™ä¿å­˜æœ€æ–°æ•°æ®ï¼Œç­‰å¾…ä¸‹æ¬¡æ›´æ–°
        ref.pending = data;
        if (!ref.timer) {
          ref.timer = setTimeout(
            () => {
              ref.lastUpdate = Date.now();
              ref.timer = null;
              if (ref.pending) {
                setThought(ref.pending);
                ref.pending = null;
              }
            },
            THROTTLE_MS - (now - ref.lastUpdate)
          );
        }
      }
    };
  }, []);

  // æ¸…ç†èŠ‚æµå®šæ—¶å™¨
  useEffect(() => {
    return () => {
      if (thoughtThrottleRef.current.timer) {
        clearTimeout(thoughtThrottleRef.current.timer);
      }
    };
  }, []);

  // ç»¼åˆè¿è¡ŒçŠ¶æ€ï¼šç­‰å¾…å“åº” æˆ– æµåœ¨è¿è¡Œ æˆ– æœ‰å·¥å…·åœ¨æ‰§è¡Œ/ç­‰å¾…ç¡®è®¤
  // Combined running state: waiting for response OR stream is running OR tools are active
  const running = waitingResponse || streamRunning || hasActiveTools;

  // è®¾ç½®å½“å‰æ´»è·ƒçš„æ¶ˆæ¯ ID / Set current active message ID
  const setActiveMsgId = useCallback((msgId: string | null) => {
    activeMsgIdRef.current = msgId;
  }, []);

  useEffect(() => {
    return ipcBridge.geminiConversation.responseStream.on((message) => {
      if (conversation_id !== message.conversation_id) {
        return;
      }

      // è¿‡æ»¤æ‰ä¸å±äºå½“å‰æ´»è·ƒè¯·æ±‚çš„äº‹ä»¶ï¼ˆé˜²æ­¢ abort åçš„äº‹ä»¶å¹²æ‰°ï¼‰
      // æ³¨æ„: åªè¿‡æ»¤ thought å’Œ start ç­‰çŠ¶æ€æ¶ˆæ¯ï¼Œå…¶ä»–æ¶ˆæ¯éƒ½å¿…é¡»æ¸²æŸ“
      // Filter out events not belonging to current active request (prevents aborted events from interfering)
      // Note: only filter out thought and start messages, other messages must be rendered
      if (activeMsgIdRef.current && message.msg_id && message.msg_id !== activeMsgIdRef.current) {
        // åªè¿‡æ»¤æ‰ thought å’Œ startï¼Œå…¶ä»–æ¶ˆæ¯éƒ½éœ€è¦æ¸²æŸ“
        // Only filter out thought and start, other messages need to be rendered
        if (message.type === 'thought') {
          return;
        }
      }

      switch (message.type) {
        case 'thought':
          throttledSetThought(message.data as ThoughtData);
          break;
        case 'start':
          setStreamRunning(true);
          setWaitingResponse(false); // æ”¶åˆ° startï¼Œå¯ä»¥æ¸…é™¤ç­‰å¾…çŠ¶æ€
          break;
        case 'finish':
          {
            setStreamRunning(false);
            // Only clear waiting state and thought when no active tools
            if (!hasActiveToolsRef.current) {
              setWaitingResponse(false);
              setThought({ subject: '', description: '' });
            }
            // Display pending KB notification AFTER agent response completes
            if (pendingKbNotification.current && !hasActiveToolsRef.current) {
              const pending = pendingKbNotification.current;
              pendingKbNotification.current = null;
              const kbMsg = transformMessage({
                type: 'content',
                conversation_id,
                msg_id: pending.msgId,
                data: pending.content,
              });
              addOrUpdateMessage(kbMsg);
            }
          }
          break;
        case 'tool_group':
          {
            // æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·åœ¨æ‰§è¡Œæˆ–ç­‰å¾…ç¡®è®¤
            // Check if any tools are executing or awaiting confirmation
            const tools = message.data as Array<{ status: string; name?: string }>;
            const activeStatuses = ['Executing', 'Confirming', 'Pending'];
            const hasActive = tools.some((tool) => activeStatuses.includes(tool.status));
            const wasActive = hasActiveToolsRef.current;
            setHasActiveTools(hasActive);

            // å½“å·¥å…·ä»æ´»è·ƒå˜ä¸ºéæ´»è·ƒæ—¶ï¼Œè®¾ç½® waitingResponse=true
            // å› ä¸ºåç«¯è¿˜éœ€è¦ç»§ç»­å‘æ¨¡å‹å‘é€è¯·æ±‚
            // When tools transition from active to inactive, set waitingResponse=true
            // because backend needs to continue sending requests to model
            if (wasActive && !hasActive && tools.length > 0) {
              setWaitingResponse(true);
            }

            // å¦‚æœæœ‰å·¥å…·åœ¨ç­‰å¾…ç¡®è®¤ï¼Œæ›´æ–° thought æç¤º
            // If tools are awaiting confirmation, update thought hint
            const confirmingTool = tools.find((tool) => tool.status === 'Confirming');
            if (confirmingTool) {
              setThought({
                subject: 'Awaiting Confirmation',
                description: confirmingTool.name || 'Tool execution',
              });
            } else if (hasActive) {
              const executingTool = tools.find((tool) => tool.status === 'Executing');
              if (executingTool) {
                setThought({
                  subject: 'Executing',
                  description: executingTool.name || 'Tool',
                });
              }
            } else if (!streamRunningRef.current) {
              // æ‰€æœ‰å·¥å…·å®Œæˆä¸”æµå·²åœæ­¢ï¼Œæ¸…é™¤ thought
              // All tools completed and stream stopped, clear thought
              setThought({ subject: '', description: '' });
            }

            // ç»§ç»­ä¼ é€’æ¶ˆæ¯ç»™æ¶ˆæ¯åˆ—è¡¨æ›´æ–°
            // Continue passing message to message list update
            addOrUpdateMessage(transformMessage(message));
          }
          break;
        case 'finished':
          {
            // å¤„ç† Finished äº‹ä»¶ï¼Œæå– token ä½¿ç”¨ç»Ÿè®¡
            // Note: 'finished' event is for token usage stats only, NOT for stream end
            // Stream end is signaled by 'finish' event
            // æ³¨æ„ï¼š'finished' äº‹ä»¶ä»…ç”¨äº token ç»Ÿè®¡ï¼Œä¸è¡¨ç¤ºæµç»“æŸ
            // æµç»“æŸç”± 'finish' äº‹ä»¶è¡¨ç¤º
            const finishedData = message.data as {
              reason?: string;
              usageMetadata?: {
                promptTokenCount?: number;
                candidatesTokenCount?: number;
                totalTokenCount?: number;
                cachedContentTokenCount?: number;
              };
            };
            if (finishedData?.usageMetadata) {
              const newTokenUsage: TokenUsageData = {
                totalTokens: finishedData.usageMetadata.totalTokenCount || 0,
              };
              setTokenUsage(newTokenUsage);
              // æŒä¹…åŒ– token ä½¿ç”¨ç»Ÿè®¡åˆ°ä¼šè¯çš„ extra.lastTokenUsage å­—æ®µ
              // ä½¿ç”¨ mergeExtra é€‰é¡¹ï¼Œåç«¯ä¼šè‡ªåŠ¨åˆå¹¶ extra å­—æ®µï¼Œé¿å…ä¸¤æ¬¡ IPC è°ƒç”¨
              void ipcBridge.conversation.update.invoke({
                id: conversation_id,
                updates: {
                  extra: {
                    lastTokenUsage: newTokenUsage,
                  } as TChatConversation['extra'],
                },
                mergeExtra: true,
              });
            }
            // DO NOT reset streamRunning/waitingResponse here!
            // For OpenAI-compatible APIs, 'finished' events are emitted per chunk
            // Only 'finish' event should reset the stream state
            // ä¸è¦åœ¨è¿™é‡Œé‡ç½® streamRunning/waitingResponseï¼
            // å¯¹äº OpenAI å…¼å®¹ APIï¼Œæ¯ä¸ªæµå—éƒ½ä¼šå‘é€ 'finished' äº‹ä»¶
            // åªæœ‰ 'finish' äº‹ä»¶æ‰åº”è¯¥é‡ç½®æµçŠ¶æ€
          }
          break;
        case 'ingest_progress': {
          const progress = message.data as typeof ingestionProgress & { fileNames?: string[]; kbMsgId?: string; kbContent?: string };
          if (progress?.status === 'kb_ready') {
            pendingKbNotification.current = {
              msgId: progress.kbMsgId || uuid(),
              content: progress.kbContent || '',
            };
          } else if (progress?.status === 'complete') {
            setIngestionProgress(progress);
            setTimeout(() => setIngestionProgress(null), 1500);
          } else {
            setIngestionProgress(progress);
          }
          break;
        }
        default: {
          if (message.type === 'error') {
            setWaitingResponse(false);
            onError?.(message as IResponseMessage);
          }
          // Backend handles persistence, Frontend only updates UI
          addOrUpdateMessage(transformMessage(message));
          break;
        }
      }
    });
    // Note: hasActiveTools and streamRunning are accessed via refs to avoid re-subscription
    // æ³¨æ„ï¼šhasActiveTools å’Œ streamRunning é€šè¿‡ ref è®¿é—®ï¼Œé¿å…é‡æ–°è®¢é˜…å¯¼è‡´äº‹ä»¶ä¸¢å¤±
  }, [conversation_id, addOrUpdateMessage, onError]);

  useEffect(() => {
    setStreamRunning(false);
    setHasActiveTools(false);
    setWaitingResponse(false);
    setThought({ subject: '', description: '' });
    setTokenUsage(null);
    setIngestionProgress(null);
    void ipcBridge.conversation.get.invoke({ id: conversation_id }).then((res) => {
      if (!res) return;
      if (res.status === 'running') {
        setStreamRunning(true);
      }
      // åŠ è½½æŒä¹…åŒ–çš„ token ä½¿ç”¨ç»Ÿè®¡
      if (res.type === 'gemini' && res.extra?.lastTokenUsage) {
        const { lastTokenUsage } = res.extra;
        // åªæœ‰å½“ lastTokenUsage æœ‰æœ‰æ•ˆæ•°æ®æ—¶æ‰è®¾ç½®
        if (lastTokenUsage.totalTokens > 0) {
          setTokenUsage(lastTokenUsage);
        }
      }
    });
  }, [conversation_id]);

  const resetState = useCallback(() => {
    setWaitingResponse(false);
    setStreamRunning(false);
    setHasActiveTools(false);
    setThought({ subject: '', description: '' });
  }, []);

  return { thought, setThought, running, tokenUsage, ingestionProgress, setActiveMsgId, setWaitingResponse, resetState };
};

const EMPTY_AT_PATH: Array<string | FileOrFolderItem> = [];
const EMPTY_UPLOAD_FILES: string[] = [];

const useSendBoxDraft = (conversation_id: string) => {
  const { data, mutate } = useGeminiSendBoxDraft(conversation_id);

  const atPath = data?.atPath ?? EMPTY_AT_PATH;
  const uploadFile = data?.uploadFile ?? EMPTY_UPLOAD_FILES;
  const content = data?.content ?? '';

  const setAtPath = useCallback(
    (atPath: Array<string | FileOrFolderItem>) => {
      mutate((prev) => ({ ...prev, atPath }));
    },
    [data, mutate]
  );

  const setUploadFile = createSetUploadFile(mutate, data);

  const setContent = useCallback(
    (content: string) => {
      mutate((prev) => ({ ...prev, content }));
    },
    [data, mutate]
  );

  return {
    atPath,
    uploadFile,
    setAtPath,
    setUploadFile,
    content,
    setContent,
  };
};

const GeminiSendBox: React.FC<{
  conversation_id: string;
  modelSelection: GeminiModelSelection;
}> = ({ conversation_id, modelSelection }) => {
  const [workspacePath, setWorkspacePath] = useState('');
  const { checkAndUpdateTitle } = useAutoTitle();
  const quotaPromptedRef = useRef<string | null>(null);
  const exhaustedModelsRef = useRef(new Set<string>());

  const { currentModel, getDisplayModelName, providers, geminiModeLookup, getAvailableModels, handleSelectModel } = modelSelection;

  const resolveFallbackTarget = useCallback(
    (exhaustedModels: Set<string>) => {
      if (!currentModel) return null;
      const provider = providers.find((item) => item.id === currentModel.id) || providers.find((item) => item.platform?.toLowerCase().includes('gemini-with-google-auth'));
      if (!provider) return null;

      const isGoogleAuthProvider = provider.platform?.toLowerCase().includes('gemini-with-google-auth');
      const manualOption = isGoogleAuthProvider ? geminiModeLookup.get('manual') : undefined;
      const manualModels = manualOption?.subModels?.map((model) => model.value) || [];
      const availableModels = isGoogleAuthProvider ? manualModels : getAvailableModels(provider);
      const candidates = availableModels.filter((model) => model && model !== currentModel.useModel && !exhaustedModels.has(model) && model !== 'manual');

      if (!candidates.length) return null;
      const scoreModel = (modelName: string) => {
        const lower = modelName.toLowerCase();
        let score = 0;
        if (lower.includes('lite')) score -= 2;
        if (lower.includes('flash')) score -= 1;
        if (lower.includes('pro')) score += 2;
        return score;
      };
      const sortedCandidates = [...candidates].sort((a, b) => {
        const scoreA = scoreModel(a);
        const scoreB = scoreModel(b);
        if (scoreA !== scoreB) return scoreA - scoreB;
        return a.localeCompare(b);
      });
      return { provider, model: sortedCandidates[0] };
    },
    [currentModel, providers, geminiModeLookup, getAvailableModels]
  );

  const isQuotaErrorMessage = useCallback((data: unknown) => {
    if (typeof data !== 'string') return false;
    const text = data.toLowerCase();
    const hasQuota = text.includes('quota') || text.includes('resource_exhausted') || text.includes('model_capacity_exhausted') || text.includes('no capacity available');
    const hasLimit = text.includes('limit') || text.includes('exceed') || text.includes('exhaust') || text.includes('status: 429') || text.includes('code 429') || text.includes('429') || text.includes('ratelimitexceeded');
    return hasQuota && hasLimit;
  }, []);

  const handleGeminiError = useCallback(
    (message: IResponseMessage) => {
      if (!isQuotaErrorMessage(message.data)) return;
      const msgId = message.msg_id || 'unknown';
      if (quotaPromptedRef.current === msgId) return;
      quotaPromptedRef.current = msgId;

      if (currentModel?.useModel) {
        exhaustedModelsRef.current.add(currentModel.useModel);
      }
      const fallbackTarget = resolveFallbackTarget(exhaustedModelsRef.current);
      if (!fallbackTarget || !currentModel || fallbackTarget.model === currentModel.useModel) {
        Message.warning('Model quota reached. Please switch to another available model.');
        return;
      }

      void handleSelectModel(fallbackTarget.provider, fallbackTarget.model).then(() => {
        Message.success(`Switched to ${fallbackTarget.model}.`);
      });
    },
    [currentModel, handleSelectModel, isQuotaErrorMessage, resolveFallbackTarget]
  );

  const { thought, running, tokenUsage, ingestionProgress, setActiveMsgId, setWaitingResponse, resetState } = useGeminiMessage(conversation_id, handleGeminiError);

  useEffect(() => {
    void ipcBridge.conversation.get.invoke({ id: conversation_id }).then((res) => {
      if (!res?.extra?.workspace) return;
      setWorkspacePath(res.extra.workspace);
    });
  }, [conversation_id]);

  const { atPath, uploadFile, setAtPath, setUploadFile, content, setContent } = useSendBoxDraft(conversation_id);

  const addOrUpdateMessage = useAddOrUpdateMessage();
  const { setSendBoxHandler } = usePreviewContext();

  // Handle initial message from guid page (stored in sessionStorage for instant page transition)
  useEffect(() => {
    const storageKey = `gemini_initial_message_${conversation_id}`;
    const storedMessage = sessionStorage.getItem(storageKey);

    if (!storedMessage || !currentModel?.useModel) return;

    // Clear immediately to prevent duplicate sends
    sessionStorage.removeItem(storageKey);

    const sendInitialMessage = async () => {
      try {
        const { input, files } = JSON.parse(storedMessage) as { input: string; files?: string[] };
        const msg_id = uuid();
        setActiveMsgId(msg_id);
        setWaitingResponse(true); // ç«‹å³è®¾ç½®ç­‰å¾…çŠ¶æ€ï¼Œç¡®ä¿æŒ‰é’®æ˜¾ç¤ºä¸ºåœæ­¢

        // Display user message immediately
        addOrUpdateMessage(
          {
            id: msg_id,
            type: 'text',
            position: 'right',
            conversation_id,
            content: {
              content: input,
            },
            createdAt: Date.now(),
          },
          true
        );

        // Send message to backend
        await ipcBridge.geminiConversation.sendMessage.invoke({
          input,
          msg_id,
          conversation_id,
          files: files || [],
        });

        void checkAndUpdateTitle(conversation_id, input);
        emitter.emit('chat.history.refresh');
        if (files && files.length > 0) {
          emitter.emit('gemini.workspace.refresh');
        }
      } catch (error) {
        log.error({ err: error }, 'Failed to send initial message:');
      }
    };

    void sendInitialMessage();
  }, [conversation_id, currentModel?.useModel]);

  // ä½¿ç”¨ useLatestRef ä¿å­˜æœ€æ–°çš„ setContent/atPathï¼Œé¿å…é‡å¤æ³¨å†Œ handler
  // Use useLatestRef to keep latest setters to avoid re-registering handler
  const setContentRef = useLatestRef(setContent);
  const atPathRef = useLatestRef(atPath);

  // æ³¨å†Œé¢„è§ˆé¢æ¿æ·»åŠ åˆ°å‘é€æ¡†çš„ handler
  // Register handler for adding text from preview panel to sendbox
  useEffect(() => {
    const handler = (text: string) => {
      // å¦‚æœå·²æœ‰å†…å®¹ï¼Œæ·»åŠ æ¢è¡Œå’Œæ–°æ–‡æœ¬ï¼›å¦åˆ™ç›´æ¥è®¾ç½®æ–‡æœ¬
      // If there's existing content, add newline and new text; otherwise just set the text
      const newContent = content ? `${content}\n${text}` : text;
      setContentRef.current(newContent);
    };
    setSendBoxHandler(handler);
  }, [setSendBoxHandler, content]);

  // Listen for sendbox.fill event to populate input from external sources
  useAddEventListener(
    'sendbox.fill',
    (text: string) => {
      setContentRef.current(text);
    },
    []
  );

  // ä½¿ç”¨å…±äº«çš„æ–‡ä»¶å¤„ç†é€»è¾‘
  const { handleFilesAdded, clearFiles } = useSendBoxFiles({
    atPath,
    uploadFile,
    setAtPath,
    setUploadFile,
  });

  const onSendHandler = async (message: string) => {
    if (!currentModel?.useModel) return;
    const msg_id = uuid();
    // è®¾ç½®å½“å‰æ´»è·ƒçš„æ¶ˆæ¯ IDï¼Œç”¨äºè¿‡æ»¤æ‰æ—§è¯·æ±‚çš„äº‹ä»¶
    // Set current active message ID to filter out events from old requests
    setActiveMsgId(msg_id);
    setWaitingResponse(true); // ç«‹å³è®¾ç½®ç­‰å¾…çŠ¶æ€ï¼Œç¡®ä¿æŒ‰é’®æ˜¾ç¤ºä¸ºåœæ­¢

    // ä¿å­˜æ–‡ä»¶åˆ—è¡¨ï¼ˆæ¸…ç©ºå‰éœ€è¦ä¿å­˜ï¼‰/ Save file list before clearing
    const filesToSend = collectSelectedFiles(uploadFile, atPath);
    const hasFiles = filesToSend.length > 0;

    // ç«‹å³æ¸…ç©ºè¾“å…¥æ¡†ï¼Œé¿å…ç”¨æˆ·è¯¯ä»¥ä¸ºæ¶ˆæ¯æ²¡å‘é€
    // Clear input immediately to avoid user thinking message wasn't sent
    setContent('');
    clearFiles();

    // User message: Display in UI immediately (Backend will persist when receiving from IPC)
    // æ˜¾ç¤ºåŸå§‹æ¶ˆæ¯ï¼Œå¹¶é™„å¸¦é€‰ä¸­æ–‡ä»¶å / Display original message with selected file names
    const displayMessage = buildDisplayMessage(message, filesToSend, workspacePath);
    addOrUpdateMessage(
      {
        id: msg_id,
        type: 'text',
        position: 'right',
        conversation_id,
        content: {
          content: displayMessage,
        },
        createdAt: Date.now(),
      },
      true
    );
    // æ–‡ä»¶é€šè¿‡ files å‚æ•°ä¼ é€’ç»™åç«¯ï¼Œä¸å†åœ¨æ¶ˆæ¯ä¸­æ·»åŠ  @ å‰ç¼€
    // Files are passed via files param, no longer adding @ prefix in message
    await ipcBridge.geminiConversation.sendMessage.invoke({
      input: displayMessage,
      msg_id,
      conversation_id,
      files: filesToSend,
    });
    void checkAndUpdateTitle(conversation_id, message);
    emitter.emit('chat.history.refresh');
    emitter.emit('gemini.selected.file.clear');
    if (hasFiles) {
      emitter.emit('gemini.workspace.refresh');
    }
  };

  useAddEventListener('gemini.selected.file', setAtPath);
  useAddEventListener('gemini.selected.file.append', (items: Array<string | FileOrFolderItem>) => {
    const merged = mergeFileSelectionItems(atPathRef.current, items);
    if (merged !== atPathRef.current) {
      setAtPath(merged as Array<string | FileOrFolderItem>);
    }
  });

  // åœæ­¢ä¼šè¯å¤„ç†å‡½æ•° Stop conversation handler
  const handleStop = async (): Promise<void> => {
    // Use finally to ensure UI state is reset even if backend stop fails
    try {
      await ipcBridge.conversation.stop.invoke({ conversation_id });
    } finally {
      resetState();
    }
  };

  return (
    <div className='max-w-800px w-full mx-auto flex flex-col mt-auto mb-16px'>
      <ThoughtDisplay thought={thought} running={running} onStop={handleStop} />

      {ingestionProgress && (
        <div className='px-3 py-2 flex items-center gap-2 text-sm' style={{ color: 'var(--color-text-2)' }}>
          <Progress percent={ingestionProgress.status === 'complete' ? 100 : ingestionProgress.status === 'stage' && ingestionProgress.percent ? ingestionProgress.percent : Math.round(((ingestionProgress.current || 0) / Math.max(ingestionProgress.total, 1)) * 100)} status={ingestionProgress.status === 'error' ? 'error' : 'normal'} size='small' style={{ flex: 1 }} />
          <span className='whitespace-nowrap text-xs'>
            {ingestionProgress.status === 'start' && `Preparing to index ${ingestionProgress.total} file(s)...`}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'extracting' && `ğŸ“„ Extracting text from ${ingestionProgress.fileName || 'document'}...`}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'setup' && 'ğŸ”Œ Connecting to embedding service...'}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'chunking' && `âœ‚ï¸ ${ingestionProgress.detail || 'Splitting document into chunks...'}`}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'embedding' && `ğŸ§  ${ingestionProgress.detail || 'Generating embeddings...'}`}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'indexing' && `ğŸ’¾ ${ingestionProgress.detail || 'Building search index...'}`}
            {ingestionProgress.status === 'stage' && ingestionProgress.stage === 'complete' && 'âœ… Indexing complete'}
            {ingestionProgress.status === 'ingesting' && `Processing ${ingestionProgress.fileName}...`}
            {ingestionProgress.status === 'success' && `Added ${ingestionProgress.fileName} to Knowledge Base`}
            {ingestionProgress.status === 'complete' && `âœ… Indexed ${ingestionProgress.successCount} file(s)`}
          </span>
        </div>
      )}

      <SendBox
        value={content}
        onChange={setContent}
        loading={running || ingestionProgress !== null}
        disabled={!currentModel?.useModel || ingestionProgress !== null}
        // å ä½æç¤ºåŒæ­¥å³ä¸Šè§’é€‰æ‹©çš„æ¨¡å‹ï¼Œç¡®ä¿ç”¨æˆ·æ„ŸçŸ¥å½“å‰ç›®æ ‡
        // Keep placeholder in sync with header selection so users know the active target
        placeholder={currentModel?.useModel ? `Send message to ${getDisplayModelName(currentModel.useModel)}` : 'No model selected for current session, cannot send message'}
        onStop={handleStop}
        className='z-10'
        onFilesAdded={handleFilesAdded}
        supportedExts={allSupportedExts}
        defaultMultiLine={true}
        lockMultiLine={true}
        tools={
          <Button
            type='secondary'
            shape='circle'
            icon={<Plus theme='outline' size='14' strokeWidth={2} fill={iconColors.primary} />}
            onClick={() => {
              void ipcBridge.dialog.showOpen.invoke({ properties: ['openFile', 'multiSelections'] }).then((files) => {
                if (files && files.length > 0) {
                  setUploadFile([...uploadFile, ...files]);
                }
              });
            }}
          />
        }
        sendButtonPrefix={<ContextUsageIndicator tokenUsage={tokenUsage} contextLimit={getModelContextLimit(currentModel?.useModel)} size={24} />}
        prefix={
          <>
            {/* Files on top */}
            {(uploadFile.length > 0 || atPath.some((item) => (typeof item === 'string' ? true : item.isFile))) && (
              <HorizontalFileList>
                {uploadFile.map((path) => (
                  <FilePreview key={path} path={path} onRemove={() => setUploadFile(uploadFile.filter((v) => v !== path))} />
                ))}
                {atPath.map((item) => {
                  const isFile = typeof item === 'string' ? true : item.isFile;
                  const path = typeof item === 'string' ? item : item.path;
                  if (isFile) {
                    return (
                      <FilePreview
                        key={path}
                        path={path}
                        onRemove={() => {
                          const newAtPath = atPath.filter((v) => (typeof v === 'string' ? v !== path : v.path !== path));
                          emitter.emit('gemini.selected.file', newAtPath);
                          setAtPath(newAtPath);
                        }}
                      />
                    );
                  }
                  return null;
                })}
              </HorizontalFileList>
            )}
            {/* Folder tags below */}
            {atPath.some((item) => (typeof item === 'string' ? false : !item.isFile)) && (
              <div className='flex flex-wrap items-center gap-8px mb-8px'>
                {atPath.map((item) => {
                  if (typeof item === 'string') return null;
                  if (!item.isFile) {
                    return (
                      <Tag
                        key={item.path}
                        color='blue'
                        closable
                        onClose={() => {
                          const newAtPath = atPath.filter((v) => (typeof v === 'string' ? true : v.path !== item.path));
                          emitter.emit('gemini.selected.file', newAtPath);
                          setAtPath(newAtPath);
                        }}
                      >
                        {item.name}
                      </Tag>
                    );
                  }
                  return null;
                })}
              </div>
            )}
          </>
        }
        onSend={onSendHandler}
      ></SendBox>
    </div>
  );
};

export default GeminiSendBox;
