# =============================================================================
# AionUI Docker Environment Configuration
# Copy to .env and customize for your deployment
# =============================================================================

# Server port (default: 25808)
AIONUI_PORT=25808

# Enable remote network access (default: true)
AIONUI_ALLOW_REMOTE=true

# Environment mode
NODE_ENV=production

# Display configuration for Xvfb
DISPLAY_NUM=99
SCREEN_RESOLUTION=1024x768x24

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
# Log level: trace|debug|info|warn|error|fatal|silent (default: info in prod, debug in dev)
# LOG_LEVEL=info

# Log format: json|pretty (default: json in prod, pretty in dev)
# LOG_FORMAT=json

# Log file path (optional — always writes JSON regardless of LOG_FORMAT)
# Enables automatic rotation by size and time
# LOG_FILE=/var/log/aionui/app.log

# Log file rotation and retention settings (when LOG_FILE is set)
# Maximum log file size before rotation (in MB)
# LOG_MAX_SIZE_MB=100

# Log retention period (in days) - controls how many rotated files to keep
# LOG_RETENTION_DAYS=30

# -----------------------------------------------------------------------------
# OpenTelemetry (OTEL) - Distributed Tracing
# -----------------------------------------------------------------------------
# Enable OpenTelemetry instrumentation and trace export
OTEL_ENABLED=false

# OTLP exporter endpoint (collector, Jaeger, Datadog, etc.)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318

# OTLP protocol (http or grpc)
OTEL_EXPORTER_OTLP_PROTOCOL=http

# Service name for trace identification
OTEL_SERVICE_NAME=aionui

# OTEL diagnostic logging (debug, info, warn, error)
# OTEL_LOG_LEVEL=info

# -----------------------------------------------------------------------------
# Syslog / SIEM Forwarding
# -----------------------------------------------------------------------------
# Enable forwarding logs to syslog/SIEM (RFC 5424 compliant)
SYSLOG_ENABLED=false

# Syslog server hostname or IP
SYSLOG_HOST=syslog.example.com

# Syslog server port (default: 514)
SYSLOG_PORT=514

# Protocol: udp, tcp, or tls
SYSLOG_PROTOCOL=udp

# Syslog facility code (0-23)
# Common values: 16 (local0), 17 (local1), 18 (local2)
SYSLOG_FACILITY=16

# -----------------------------------------------------------------------------
# Langfuse - LLM Observability
# -----------------------------------------------------------------------------
# Enable Langfuse tracing for LLM interactions
LANGFUSE_ENABLED=false

# Langfuse cloud or self-hosted instance URL
LANGFUSE_HOST=https://cloud.langfuse.com

# Langfuse API credentials (from project settings)
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=

# -----------------------------------------------------------------------------
# Global Shared Models (optional — pre-configure models for all users)
# -----------------------------------------------------------------------------
# JSON array of model configurations available to all users.
# Synced to DB on startup. Admin UI can further manage these.
# See global-models-example.json for a complete example with multiple providers.
#
# Mount a file instead (recommended for production):
GLOBAL_MODELS_FILE=/etc/aionui/global-models.json
# Or use JSON env var (for simple configs):
# GLOBAL_MODELS='[{"platform":"openai","name":"GPT-4","api_key":"sk-xxx","models":["gpt-4","gpt-4o"]}]'
#
# Schema per model:
#   platform: string (required) - Provider ID (openai, anthropic, azure-openai, etc.)
#   name: string (required) - Display name
#   models: string[] (required) - List of model IDs
#   api_key: string (optional) - API key (encrypted in DB)
#   base_url: string (optional) - Custom API endpoint
#   capabilities: string[] (optional) - e.g., ["vision", "function_calling"]
#   context_limit: number (optional) - Token context limit
#   custom_headers: object (optional) - Additional HTTP headers
#   enabled: boolean (optional, default: true)
#   priority: number (optional, default: 0) - Sort order (higher = first)

# -----------------------------------------------------------------------------
# Security (REQUIRED for production)
# -----------------------------------------------------------------------------
# Set a secure random secret for JWT token signing
# Generate with: openssl rand -base64 32
# JWT_SECRET=your-secure-random-secret-key

# Set initial admin password (optional)
# If unset, a random password is auto-generated and printed to container logs on first run.
# Only takes effect when admin has no existing password (first run or fresh database).
# Will NOT overwrite a user-changed password on container restart.
# Generate with: openssl rand -base64 24 | tr -d '/+=' | head -c 32
# AIONUI_ADMIN_PASSWORD=your-secure-admin-password

# Enable HTTPS (requires reverse proxy configuration)
# AIONUI_HTTPS=true

# Trust proxy — set when behind a reverse proxy (nginx, Traefik, Caddy).
# Required for correct client IP logging, secure cookies, and HSTS.
# Values: true (trust all), 1 (single proxy hop), "loopback" (localhost only),
#         CIDR like "172.16.0.0/12" (Docker network), false or unset (disabled)
# AIONUI_TRUST_PROXY=1

# -----------------------------------------------------------------------------
# OIDC / EntraID SSO (optional — enables "Sign in with Microsoft")
# -----------------------------------------------------------------------------
# OIDC_ENABLED=true
# OIDC_ISSUER=https://login.microsoftonline.com/{tenant-id}/v2.0
# OIDC_CLIENT_ID=your-client-id
# OIDC_CLIENT_SECRET=your-client-secret
# OIDC_REDIRECT_URI=http://localhost:25808/api/auth/oidc/callback
# OIDC_SCOPES=openid profile email
# OIDC_GROUPS_CLAIM=groups

# EntraID group → role mappings 
# mount a file instead (Recommended for production):
GROUP_MAPPINGS_FILE=/etc/aionui/group-mappings.json
# Or use (JSON array)
# GROUP_MAPPINGS_JSON=[{"groupId":"<group-object-id>","groupName":"AI-Admins","role":"admin"},{"groupId":"<group-object-id>","groupName":"AI-Users","role":"user"}]

# -----------------------------------------------------------------------------
# Branding (optional — for custom forks)
# -----------------------------------------------------------------------------
# Override default branding. Leave unset to use built-in defaults.
# AIONUI_BRAND_NAME=AionUI
# AIONUI_GITHUB_REPO=jrmatherly/aionui
# AIONUI_WEBSITE_URL=https://github.com/jrmatherly/aionui
# AIONUI_CONTACT_URL=https://github.com/jrmatherly/aionui/issues
# AIONUI_FEEDBACK_URL=https://github.com/jrmatherly/aionui/issues

# -----------------------------------------------------------------------------
# Feature Flags
# -----------------------------------------------------------------------------
# YOLO Mode toggles — allow users to toggle "Skip Permissions" in Tools settings.
# Hidden by default for safety — only enable when administrators explicitly allow
# unattended/autonomous execution without permission prompts.
#
# Claude YOLO: Allows Claude Code to run without asking for tool-use permissions
# ALLOW_CLAUDE_YOLO=false
#
# Gemini YOLO: Allows Gemini CLI to run without asking for tool-use permissions
# ALLOW_GEMINI_YOLO=false

# =============================================================================
# Multi-Agent Mode
# =============================================================================
# All CLI tools are baked into the image by default:
#   Claude, Qwen, Codex, iFlow, Auggie, Copilot, Qoder, OpenCode
#
# To disable specific tools at runtime, set DISABLE_CLI_<NAME>=true
# DISABLE_CLI_CLAUDE=true
# DISABLE_CLI_QWEN=true
# DISABLE_CLI_CODEX=true
# DISABLE_CLI_IFLOW=true
# DISABLE_CLI_AUGGIE=true
# DISABLE_CLI_COPILOT=true
# DISABLE_CLI_QODER=true
# DISABLE_CLI_OPENCODE=true

# =============================================================================
# Multi-Agent Mode — API Keys (runtime)
# =============================================================================
# Container-level API keys for CLI tools.
# Users can also set personal keys via the UI (Settings → API Keys).
# Per-user keys take precedence over container-level keys.
#
# -----------------------------------------------------------------------------
# CLI Tool API Keys
# -----------------------------------------------------------------------------
# Claude Code (Anthropic)
# ANTHROPIC_API_KEY=sk-ant-xxx
#
# Codex, OpenCode (OpenAI)
# OPENAI_API_KEY=sk-xxx
#
# Gemini (Google AI Studio)
# GEMINI_API_KEY=xxx

# -----------------------------------------------------------------------------
# Knowledge Base / RAG (Embeddings Configuration)
# -----------------------------------------------------------------------------
# Configure the embedding provider for document ingestion and semantic search.
# Supports any OpenAI-compatible endpoint (OpenAI, Azure, LiteLLM, vLLM, etc.)
#
# EMBEDDING_API_KEY: API key for your embedding provider (required)
# EMBEDDING_API_BASE: Base URL for OpenAI-compatible endpoint (optional)
# EMBEDDING_MODEL: Embedding model name (default: text-embedding-3-small)
# EMBEDDING_DIMENSIONS: Vector dimensions (optional, auto-detected for OpenAI models)
#   Common values: text-embedding-3-small=1536, text-embedding-3-large=3072
#   Set explicitly for custom models or endpoints that don't report dimensions
#
# Dimension comparison:
# ┌────────────────────────┬────────────┬─────────┬────────┐
# │ Model                  │ Dimensions │ Quality │ Cost   │
# ├────────────────────────┼────────────┼─────────┼────────┤
# │ text-embedding-3-small │ 1536       │ Good    │ Lower  │
# ├────────────────────────┼────────────┼─────────┼────────┤
# │ text-embedding-3-large │ 3072       │ Better  │ Higher │
# └────────────────────────┴────────────┴─────────┴────────┘
#
# Examples:
#
# Direct OpenAI:
#   EMBEDDING_API_KEY=sk-xxx
#
# Azure OpenAI:
#   EMBEDDING_API_KEY=your-azure-key
#   EMBEDDING_API_BASE=https://your-resource.openai.azure.com/
#
# LiteLLM Gateway:
#   EMBEDDING_API_KEY=your-gateway-key
#   EMBEDDING_API_BASE=http://litellm:4000/v1
#
# Self-hosted (vLLM, LocalAI, etc.):
#   EMBEDDING_API_KEY=dummy  # Some servers require a key even if not validated
#   EMBEDDING_API_BASE=http://localhost:8000/v1
#
# Falls back to OPENAI_API_KEY if EMBEDDING_API_KEY not set.
# EMBEDDING_API_KEY=
# EMBEDDING_API_BASE=
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSIONS=

# -----------------------------------------------------------------------------
# Image Generation
# -----------------------------------------------------------------------------
# Pre-configure image generation on first startup.
# Requires a global model provider with an image-capable model (e.g., gpt-image-1).
#
# IMAGE_GENERATION_ENABLED: Set to "true" to auto-enable image generation.
#   Only applies when no user has configured image gen yet (first run).
# IMAGE_GENERATION_MODEL: Model name to select (must exist in a global model provider).
#   If omitted, auto-detects the first model with "image" or "banana" in the name.
# IMAGE_GENERATION_PROVIDER: Global model provider name to use (matches "name" field
#   in global-models.json). If omitted, auto-detects from all providers.
IMAGE_GENERATION_ENABLED=true
# IMAGE_GENERATION_MODEL=gpt-image-1
# IMAGE_GENERATION_PROVIDER=

# -----------------------------------------------------------------------------
# Multi-Agent Mode — OAuth CLIs
# -----------------------------------------------------------------------------
# GitHub Copilot — uses OAuth authentication (no API key needed)
# Auggie (Augment) — uses OAuth authentication (no API key needed)
#
# -----------------------------------------------------------------------------
# Per-User API Keys (available in Settings → API Keys UI)
# -----------------------------------------------------------------------------
# Common Providers:
#   - Anthropic (Claude)
#   - Azure OpenAI
#   - Gemini (Google AI Studio)
#   - OpenAI (GPT, Codex)
#
# Other Providers:
#   - Cohere
#   - Groq
#   - OpenRouter
#   - Perplexity
